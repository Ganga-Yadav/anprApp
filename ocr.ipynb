{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257e4def-5389-4ef2-968b-5c0cbdc39c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util, visualization_utils as viz_utils\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "import time as tm  # Import the time module with an alias\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64c6ec-c873-4a88-a9e3-57085d4c160e",
   "metadata": {},
   "source": [
    "##### *Play with image*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830d5821-2cdc-484e-acf9-3565eaf19971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DLL1LAF6228'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMAGE_PATH = r'D:\\anprNew\\Detected_Images\\img (62).jpg'\n",
    "IMAGE_PATH =r'C:\\Users\\Msdn08\\Desktop\\Test_Img\\testOcr\\test (1).jpg'\n",
    "# Define paths\n",
    "MODEL_PATH = 'D:\\\\anprNew\\\\ocrModel\\\\export\\\\saved_model'\n",
    "LABEL_MAP_NAME_1 = 'label_map.pbtxt'\n",
    "ANNOTATION_PATH = os.path.join('Tensorflow', 'workspace', 'annotations_ocr')\n",
    "LABELMAP = os.path.join(ANNOTATION_PATH, LABEL_MAP_NAME_1)\n",
    "\n",
    "# Ensure annotation path exists\n",
    "os.makedirs(ANNOTATION_PATH, exist_ok=True)\n",
    "\n",
    "# Create label map\n",
    "labels = [\n",
    "    {'name':'1', 'id':1}, {'name':'2', 'id':2}, {'name':'3', 'id':3}, \n",
    "    {'name':'4', 'id':4}, {'name':'5', 'id':5}, {'name':'6', 'id':6},\n",
    "    {'name':'7', 'id':7}, {'name':'8', 'id':8}, {'name':'9', 'id':9}, \n",
    "    {'name':'0', 'id':10},\n",
    "    {'name':'A', 'id':11}, {'name':'B', 'id':12},\n",
    "    {'name':'C', 'id':13}, {'name':'D', 'id':14}, {'name':'E', 'id':15}, \n",
    "    {'name':'F', 'id':16}, {'name':'G', 'id':17}, {'name':'H', 'id':18},\n",
    "    {'name':'I', 'id':19}, {'name':'J', 'id':20}, {'name':'K', 'id':21}, \n",
    "    {'name':'L', 'id':22}, {'name':'M', 'id':23}, {'name':'N', 'id':24},\n",
    "    {'name':'O', 'id':25}, {'name':'P', 'id':26}, {'name':'Q', 'id':27}, \n",
    "    {'name':'R', 'id':28}, {'name':'S', 'id':29}, {'name':'T', 'id':30},\n",
    "    {'name':'U', 'id':31}, {'name':'V', 'id':32}, {'name':'W', 'id':33}, \n",
    "    {'name':'X', 'id':34}, {'name':'Y', 'id':35}, {'name':'Z', 'id':36},\n",
    "]\n",
    "\n",
    "with open(LABELMAP, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "\n",
    "# Load the TensorFlow saved model\n",
    "model = tf.saved_model.load(MODEL_PATH)\n",
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "# Assuming the function signature is 'serving_default' and it takes an image tensor\n",
    "infer = model.signatures['serving_default']\n",
    "\n",
    "# Define the detection function\n",
    "def detect_fn(image):\n",
    "    input_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)  # Convert to uint8\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    output_dict = infer(input_tensor)\n",
    "    return output_dict\n",
    "\n",
    "# Read and preprocess the input image\n",
    "#IMAGE_PATH = r'D:\\anprNew\\Detected_Images\\img (62).jpg'\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "# Run detection\n",
    "detections = detect_fn(image_np)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "# Visualization\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "min_threshold=0.2\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes'] + label_id_offset,\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=10,\n",
    "    min_score_thresh=min_threshold,\n",
    "    agnostic_mode=False\n",
    ")\n",
    "#previous_text = None  # Initialize previous_text variable\n",
    "try:\n",
    "    text =get_serialized_detected_labels_bothRows(detections, category_index, min_threshold)\n",
    "    if text != previous_text:  # Check if the current text is different from the previous one    os.makedirs(folder_path)\n",
    "        save_results(text)\n",
    "        previous_text = text  # Update the previous_text variable\n",
    "except:\n",
    "    pass\n",
    "# Display the result\n",
    "#plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()\n",
    "previous_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1a44a-78b4-43d4-8422-56a307ba0719",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *play with video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d5065-b751-4d5d-8149-a04f66768b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util, visualization_utils as viz_utils\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Define paths\n",
    "MODEL_PATH = 'D:\\\\anprNew\\\\ocrModel\\\\export\\\\saved_model'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "ANNOTATION_PATH = os.path.join('Tensorflow', 'workspace', 'annotations_ocr')\n",
    "LABELMAP = os.path.join(ANNOTATION_PATH, LABEL_MAP_NAME)\n",
    "\n",
    "# Ensure annotation path exists\n",
    "os.makedirs(ANNOTATION_PATH, exist_ok=True)\n",
    "\n",
    "# Create label map\n",
    "labels = [\n",
    "    {'name':'1', 'id':1}, {'name':'2', 'id':2}, {'name':'3', 'id':3}, \n",
    "    {'name':'4', 'id':4},{'name':'5', 'id':5}, {'name':'6', 'id':6},\n",
    "    {'name':'7', 'id':7}, {'name':'8', 'id':8}, {'name':'9', 'id':9}, \n",
    "    {'name':'0', 'id':10},\n",
    "    {'name':'A', 'id':11}, {'name':'B', 'id':12},\n",
    "    {'name':'C', 'id':13}, {'name':'D', 'id':14}, {'name':'E', 'id':15}, \n",
    "    {'name':'F', 'id':16},{'name':'G', 'id':17}, {'name':'H', 'id':18},\n",
    "    {'name':'I', 'id':19}, {'name':'J', 'id':20}, {'name':'K', 'id':21}, \n",
    "    {'name':'L', 'id':22},{'name':'M', 'id':23}, {'name':'N', 'id':24},\n",
    "    {'name':'O', 'id':25}, {'name':'P', 'id':26}, {'name':'Q', 'id':27}, \n",
    "    {'name':'R', 'id':28},{'name':'S', 'id':29}, {'name':'T', 'id':30},\n",
    "    {'name':'U', 'id':31}, {'name':'V', 'id':32}, {'name':'W', 'id':33}, \n",
    "    {'name':'X', 'id':34},{'name':'Y', 'id':35}, {'name':'Z', 'id':36},\n",
    "    ]\n",
    "with open(LABELMAP, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "\n",
    "# Load the TensorFlow saved model\n",
    "model = tf.saved_model.load(MODEL_PATH)\n",
    "\n",
    "# Assuming the function signature is 'serving_default' and it takes an image tensor\n",
    "infer = model.signatures['serving_default']\n",
    "\n",
    "# Define the detection function\n",
    "def detect_fn(image):\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    output_dict = infer(input_tensor)\n",
    "    return output_dict\n",
    "\n",
    "# Set up video capture\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\Msdn08\\Desktop\\Test_Img\\testOcr1row.mp4')\n",
    "\n",
    "# Create category index\n",
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "\n",
    "# Processing frames in the video\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert frame to numpy array\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    # Run detection\n",
    "    detections = detect_fn(image_np)\n",
    "    \n",
    "    # Extract items from the detections dictionary\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    # Visualization of the results of a detection\n",
    "    label_id_offset = 0\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    detection_threshold = 0.3\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=5,\n",
    "        min_score_thresh=detection_threshold,\n",
    "        agnostic_mode=False     \n",
    "    )\n",
    "\n",
    "    # Display output\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (900, 700)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d981650-abfb-428c-bd54-90f69e7663cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Operational Functions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b29feb-d218-4a0f-b1c4-ff25a8342175",
   "metadata": {},
   "source": [
    "##### ***OCR for both 1row and 2rows (still facing some issues when single row licence plate is right side up)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c2a1e2-aad3-45f2-aafe-acb0dda388b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_serialized_detected_labels_bothRows(detections, category_index, score_threshold):\n",
    "    # Extract the class IDs, scores, and bounding boxes from the detections\n",
    "    classes = detections['detection_classes']\n",
    "    scores = detections['detection_scores']\n",
    "    boxes = detections['detection_boxes']\n",
    "\n",
    "    # Initialize a list to hold sorted labels for each row\n",
    "    sorted_labels_rows = []\n",
    "\n",
    "    # Determine the number of rows by clustering y-coordinates of bounding boxes\n",
    "    # For simplicity, we're assuming there are only two rows and we determine the\n",
    "    # cutoff by taking the median of the y-coordinates of the bounding box centers\n",
    "    box_centers = [((box[0] + box[2]) / 2) for box in boxes]\n",
    "    y_cutoff = np.median(box_centers)\n",
    "\n",
    "    # Split the detections into two rows based on the y_cutoff\n",
    "    row_1 = []\n",
    "    row_2 = []\n",
    "    for score, cls, box in zip(scores, classes, boxes):\n",
    "        if score >= score_threshold:\n",
    "            center_y = (box[0] + box[2]) / 2\n",
    "            if center_y < y_cutoff:\n",
    "                row_1.append((score, cls, box))\n",
    "            else:\n",
    "                row_2.append((score, cls, box))\n",
    "\n",
    "    # Sort each row by the x-coordinate of the bounding box\n",
    "    row_1_sorted = sorted(row_1, key=lambda x: x[2][1])\n",
    "    row_2_sorted = sorted(row_2, key=lambda x: x[2][1])\n",
    "\n",
    "    # Function to convert sorted detection info to label string for a row\n",
    "    def get_labels_for_row(sorted_row):\n",
    "        labels = []\n",
    "        for score, cls, box in sorted_row:\n",
    "            class_id = cls + label_id_offset  # Adjusting for 1-based indexing\n",
    "            label = category_index.get(class_id, {}).get('name', '')\n",
    "            labels.append(label)\n",
    "        return ''.join(labels)\n",
    "\n",
    "    # Get the sorted labels for each row\n",
    "    sorted_labels_rows.append(get_labels_for_row(row_1_sorted))\n",
    "    sorted_labels_rows.append(get_labels_for_row(row_2_sorted))\n",
    "\n",
    "    # Concatenate the labels from both rows into a single string\n",
    "    detected_labels_string = ''.join(sorted_labels_rows)\n",
    "\n",
    "    return detected_labels_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a750a8e0-7101-4498-8d92-3b341b4e8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_detected_labels_singleRow(detections, category_index, score_threshold):\n",
    "    \"\"\"\n",
    "    Constructs a string of detected labels sorted by their position in the image.\n",
    "\n",
    "    Args:\n",
    "    detections (dict): The detections dictionary from the model's output.\n",
    "    category_index (dict): A dictionary mapping class IDs to class labels.\n",
    "    score_threshold (float): The threshold for detection scores.\n",
    "\n",
    "    Returns:\n",
    "    str: A concatenated string of detected labels sorted by their x-coordinates.\n",
    "    \"\"\"\n",
    "    # Extract the class IDs, scores, and bounding boxes from the detections\n",
    "    classes = detections['detection_classes']\n",
    "    scores = detections['detection_scores']\n",
    "    boxes = detections['detection_boxes']\n",
    "\n",
    "    # Filter and sort the detections by the score threshold and x-coordinate of the bounding box\n",
    "    sorted_labels = []\n",
    "    for score, cls, box in sorted(zip(scores, classes, boxes), key=lambda x: x[2][1]):\n",
    "        if score >= score_threshold:\n",
    "            class_id = cls + label_id_offset  # Adjusting for 1-based indexing\n",
    "            label = category_index.get(class_id, {}).get('name', '')\n",
    "            sorted_labels.append(label)\n",
    "\n",
    "    # Concatenate the labels to form a string\n",
    "    detected_labels_string = ''.join(sorted_labels)\n",
    "\n",
    "    return detected_labels_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea3abb-08af-43ac-90a3-d8e6e5798b46",
   "metadata": {},
   "source": [
    "##### ***save the ocr result***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "053a9413-f26d-4c45-94e9-62fb158e9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(text):\n",
    "    # Fix the folder path\n",
    "    folder_path = 'DetectedResult'\n",
    "    \n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Get the current date\n",
    "    current_date = datetime.now().strftime('%Y%m%d')\n",
    "    \n",
    "    # Construct the full file path including the folder path and the CSV filename with date\n",
    "    file_path = os.path.join(folder_path, f\"Detected_results_{current_date}.csv\")\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(file_path):\n",
    "        # If the file doesn't exist, create it\n",
    "        with open(file_path, mode='w', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            # Write a header row if needed\n",
    "            #csv_writer.writerow(['Text'])\n",
    "    \n",
    "    # Append the text to the CSV file\n",
    "    with open(file_path, mode='a', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea192fc6-2ffc-4315-9a1a-47a5bb662a9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### ***accumulate all code for perform Ocr_detection in one function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0851d1-878f-4f7f-8bb0-d592b3a96e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_detection(random_image):\n",
    "    IMAGE_PATH = random_image\n",
    "    #IMAGE_PATH = random_image + '.jpg'  # Append '.jpg' to the image path\n",
    "    # Define paths\n",
    "    MODEL_PATH = 'D:\\\\anprNew\\\\ocrModel\\\\export\\\\saved_model'\n",
    "    ANNOTATION_PATH = os.path.join('Tensorflow', 'workspace', 'annotations_ocr')\n",
    "    LABEL_MAP_NAME_1 = 'label_map.pbtxt'\n",
    "    LABELMAP = os.path.join(ANNOTATION_PATH, LABEL_MAP_NAME_1)\n",
    "\n",
    "    # Ensure annotation path exists\n",
    "    os.makedirs(ANNOTATION_PATH, exist_ok=True)\n",
    "\n",
    "    # Create label map\n",
    "    labels = [\n",
    "        {'name':'1', 'id':1}, {'name':'2', 'id':2}, {'name':'3', 'id':3}, \n",
    "        {'name':'4', 'id':4}, {'name':'5', 'id':5}, {'name':'6', 'id':6},\n",
    "        {'name':'7', 'id':7}, {'name':'8', 'id':8}, {'name':'9', 'id':9}, \n",
    "        {'name':'0', 'id':10},\n",
    "        {'name':'A', 'id':11}, {'name':'B', 'id':12},\n",
    "        {'name':'C', 'id':13}, {'name':'D', 'id':14}, {'name':'E', 'id':15}, \n",
    "        {'name':'F', 'id':16}, {'name':'G', 'id':17}, {'name':'H', 'id':18},\n",
    "        {'name':'I', 'id':19}, {'name':'J', 'id':20}, {'name':'K', 'id':21}, \n",
    "        {'name':'L', 'id':22}, {'name':'M', 'id':23}, {'name':'N', 'id':24},\n",
    "        {'name':'O', 'id':25}, {'name':'P', 'id':26}, {'name':'Q', 'id':27}, \n",
    "        {'name':'R', 'id':28}, {'name':'S', 'id':29}, {'name':'T', 'id':30},\n",
    "        {'name':'U', 'id':31}, {'name':'V', 'id':32}, {'name':'W', 'id':33}, \n",
    "        {'name':'X', 'id':34}, {'name':'Y', 'id':35}, {'name':'Z', 'id':36},\n",
    "    ]\n",
    "\n",
    "    with open(LABELMAP, 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write('item { \\n')\n",
    "            f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "            f.write('\\tid:{}\\n'.format(label['id']))\n",
    "            f.write('}\\n')\n",
    "\n",
    "    # Load the TensorFlow saved model\n",
    "    model = tf.saved_model.load(MODEL_PATH)\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "    # Assuming the function signature is 'serving_default' and it takes an image tensor\n",
    "    infer = model.signatures['serving_default']\n",
    "\n",
    "    # Define the detection function\n",
    "    def detect_fn(image):\n",
    "        input_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)  # Convert to uint8\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        output_dict = infer(input_tensor)\n",
    "        return output_dict\n",
    "\n",
    "    # Read and preprocess the input image\n",
    "    img = cv2.imread(IMAGE_PATH)\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    # Run detection\n",
    "    detections = detect_fn(image_np)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    # Visualization\n",
    "    label_id_offset = 0\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    min_threshold = 0.2\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=10,\n",
    "        min_score_thresh=min_threshold,\n",
    "        agnostic_mode=False\n",
    "    )\n",
    "    \n",
    "    textRow1 =get_sorted_detected_labels_singleRow(detections, category_index, min_threshold)\n",
    "    textBothRow =get_serialized_detected_labels_bothRows(detections, category_index,min_threshold)\n",
    "    # Display the result\n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    return textBothRow ,textRow1\n",
    "\n",
    "# Example usage:\n",
    "#random_image_path = r'D:\\anprNew\\Detected_Images\\img (62)'\n",
    "#perform_detection(random_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bab09-83ff-463c-86ed-1ba152e6ee60",
   "metadata": {},
   "source": [
    "##### ***testing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75906b-75e6-494a-bdb9-9ccac2d7fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'D:\\\\AnprProject\\\\myModels\\\\tfodModel\\\\export\\\\saved_model'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "#ANNOTATION_PATH = os.path.join('Tensorflow', 'workspace', 'annotations')\n",
    "ANNOTATION_PATH = os.path.join('Annotations','annotations_tfod')\n",
    "LABELMAP = os.path.join(ANNOTATION_PATH, LABEL_MAP_NAME)\n",
    "\n",
    "# Ensure annotation path exists\n",
    "os.makedirs(ANNOTATION_PATH, exist_ok=True)\n",
    "\n",
    "# Create label map\n",
    "labels = [{'name':'licence', 'id':1}]\n",
    "with open(LABELMAP, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "\n",
    "# Load the TensorFlow saved model\n",
    "model = tf.saved_model.load(MODEL_PATH)\n",
    "category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "# Assuming the function signature is 'serving_default' and it takes an image tensor\n",
    "infer = model.signatures['serving_default']\n",
    "\n",
    "# Define the detection function\n",
    "def detect_fn(image):\n",
    "    input_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)  # Convert to uint8\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    output_dict = infer(input_tensor)\n",
    "    return output_dict\n",
    "\n",
    "# Read and preprocess the input image\n",
    "IMAGE_PATH = r'C:\\Users\\Msdn08\\Desktop\\Test_Img\\img (322).jpg'\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "# Run detection\n",
    "detections = detect_fn(image_np)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# Convert detection_classes to integers\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(int)\n",
    "\n",
    "# Visualization\n",
    "label_id_offset = 0\n",
    "image_np_with_detections = image_np.copy()\n",
    "min_threshold=0.6\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes'] + label_id_offset,  # Ensure detection classes are integers\n",
    "    detections['detection_scores'],\n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=10,\n",
    "    min_score_thresh=min_threshold,\n",
    "    agnostic_mode=False\n",
    ")\n",
    "\n",
    "#try:\n",
    "region=roi_it(image_np_with_detections,detections,min_threshold)   \n",
    "#save_results(region,'Detected_Images')\n",
    "#except:\n",
    "    #pass\n",
    "\n",
    "# Display the result\n",
    "#plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()\n",
    "\n",
    "#random_image_path = r'D:\\anprNew\\Detected_Images\\img (62)'\n",
    "#random_image_path=region\n",
    "#bothrow,row1=perform_detection(region)\n",
    "#print (row1, bothrow)\n",
    "\n",
    "regions_paths = roi_it(image_np_with_detections, detections, min_threshold)\n",
    "\n",
    "# Assuming perform_detection accepts the path of the region image as input\n",
    "for region_path in regions_paths:\n",
    "    bothrow,row1=perform_detection(region_path)\n",
    "print (bothrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25218f4-a513-43e5-a2e5-c7eb6f73324b",
   "metadata": {},
   "source": [
    "##### ***new roi_it***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77746238-8884-4b61-9c97-9c184cc2aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def roi_it(image, detections, detection_threshold, save_dir='regions'):\n",
    "    # Create a directory to save the regions if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # scores, boxes, and classes above threshold\n",
    "    scores = list(filter(lambda x: x > detection_threshold, detections['detection_scores']))\n",
    "    boxes = detections['detection_boxes'][:len(scores)]\n",
    "    classes = detections['detection_classes'][:len(scores)]\n",
    "\n",
    "    # full image dimension\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    \n",
    "    region_paths = []  # List to store the paths of saved region images\n",
    "    \n",
    "    # Apply ROI filtering and OCR\n",
    "    for indx, box in enumerate(boxes):    \n",
    "        roi = box * [height, width, height, width]\n",
    "        region = image[int(roi[0]):int(roi[2]), int(roi[1]):int(roi[3])]  # Actual region extracting image\n",
    "        \n",
    "        current_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\") #seperate YearMonthDate_hourMinutesSecond_milisecond \n",
    "        img_name = '{}.jpg'.format(current_datetime)\n",
    "        # Check if the folder exists, if not, create it\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        cv2.imwrite(os.path.join(save_dir, img_name), region)\n",
    "        region_paths.append(os.path.join(save_dir, img_name))\n",
    "    \n",
    "    return region_paths  # Return the list of paths to saved region images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d9549-6875-4a8b-bb87-cd78c19ab6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
