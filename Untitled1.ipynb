{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a00113-8f57-4e78-b072-99cdb258059a",
   "metadata": {},
   "source": [
    " #### ***Import Libraries and Define loadModels Class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e69139-d504-4f79-9752-b330d7e5baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util, visualization_utils as viz_utils\n",
    "import cv2  \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class loadModels:\n",
    "    paths = {\n",
    "        'OCR_MODEL_PATH': os.path.join('myModels', 'ocrModel', 'export', 'saved_model'),\n",
    "        'LPR_MODEL_PATH': os.path.join('myModels', 'ocrModel', 'export', 'saved_model'),\n",
    "        'OCR_LABELMAP_PATH': os.path.join('Annotations', 'annotations_ocr', 'label_map.pbtxt'),\n",
    "        'LPR_LABELMAP_PATH': os.path.join('Annotations', 'annotations_lpr', 'label_map.pbtxt'),\n",
    "    }\n",
    "\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "        self.load_models()\n",
    "\n",
    "    def load_models(self):\n",
    "        self.ocr_model = tf.saved_model.load(self.paths['OCR_MODEL_PATH'])\n",
    "        self.lpr_model = tf.saved_model.load(self.paths['LPR_MODEL_PATH'])\n",
    "\n",
    "        self.ocr_category_index = label_map_util.create_category_index_from_labelmap(self.paths['OCR_LABELMAP_PATH'])\n",
    "        self.lpr_category_index = label_map_util.create_category_index_from_labelmap(self.paths['LPR_LABELMAP_PATH'])\n",
    "\n",
    "        self.ocr_infer = self.ocr_model.signatures['serving_default']\n",
    "        self.lpr_infer = self.lpr_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d787ab-726f-416d-9241-cb4a81864156",
   "metadata": {},
   "source": [
    "### ***Define the performObjectDetection class***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b26551-3a20-46c0-b34b-6693c28e563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class performObjectDetection(loadModels):\n",
    "    LABELS_OCR = [\n",
    "        {'name':'1', 'id':1}, {'name':'2', 'id':2}, {'name':'3', 'id':3}, \n",
    "        {'name':'4', 'id':4}, {'name':'5', 'id':5}, {'name':'6', 'id':6},\n",
    "        {'name':'7', 'id':7}, {'name':'8', 'id':8}, {'name':'9', 'id':9}, \n",
    "        {'name':'0', 'id':10},\n",
    "        {'name':'A', 'id':11}, {'name':'B', 'id':12},\n",
    "        {'name':'C', 'id':13}, {'name':'D', 'id':14}, {'name':'E', 'id':15}, \n",
    "        {'name':'F', 'id':16}, {'name':'G', 'id':17}, {'name':'H', 'id':18},\n",
    "        {'name':'I', 'id':19}, {'name':'J', 'id':20}, {'name':'K', 'id':21}, \n",
    "        {'name':'L', 'id':22}, {'name':'M', 'id':23}, {'name':'N', 'id':24},\n",
    "        {'name':'O', 'id':25}, {'name':'P', 'id':26}, {'name':'Q', 'id':27}, \n",
    "        {'name':'R', 'id':28}, {'name':'S', 'id':29}, {'name':'T', 'id':30},\n",
    "        {'name':'U', 'id':31}, {'name':'V', 'id':32}, {'name':'W', 'id':33}, \n",
    "        {'name':'X', 'id':34}, {'name':'Y', 'id':35}, {'name':'Z', 'id':36},\n",
    "    ]\n",
    "    LABELS_LPR = [{'name':'licence', 'id':1}]\n",
    "    \n",
    "    def __init__(self, paths):\n",
    "        super().__init__(paths)\n",
    "\n",
    "    def load_model_and_label_map(self, model_path, label_map_path):\n",
    "        model = tf.saved_model.load(model_path)\n",
    "        category_index = label_map_util.create_category_index_from_labelmap(label_map_path)\n",
    "        infer = model.signatures['serving_default']\n",
    "        return model, category_index, infer\n",
    "\n",
    "    def detect_objects(self, image_np, infer):\n",
    "        input_tensor = tf.convert_to_tensor(image_np, dtype=tf.uint8)\n",
    "        input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        output_dict = infer(input_tensor)\n",
    "        num_detections = int(output_dict.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in output_dict.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(int)\n",
    "        return detections\n",
    "\n",
    "    def run_object_detection(self, image_path, model, infer, min_threshold=0.6):\n",
    "        img = cv2.imread(image_path)\n",
    "        image_np = np.array(img)\n",
    "        detections = self.detect_objects(image_np, infer)\n",
    "        return detections\n",
    "\n",
    "    def run_object_detection_and_ocr(self, image_path, model_path, label_map_path, min_threshold=0.6):\n",
    "        model, category_index, infer = self.load_model_and_label_map(model_path, label_map_path)\n",
    "        detections = self.run_object_detection(image_path, model, infer, min_threshold)\n",
    "        \n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(int)\n",
    "        \n",
    "        # Visualization\n",
    "        label_id_offset = 0\n",
    "        image_np_with_detections = cv2.imread(image_path)\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes'] + label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=min_threshold,\n",
    "            agnostic_mode=False\n",
    "        )\n",
    "\n",
    "        regions_paths = self.roi_it(image_np_with_detections, detections, min_threshold)\n",
    "\n",
    "        ocr_results = []\n",
    "        for region_path in regions_paths:\n",
    "            both_row, row1 = self.perform_ocr_detection_from_image(region_path)\n",
    "            ocr_results.append((both_row, row1))\n",
    "\n",
    "        return ocr_results\n",
    "\n",
    "    def perform_ocr_detection_from_image(self, image_path):\n",
    "        # Get paths\n",
    "        MODEL_PATH = self.paths['OCR_MODEL_PATH']\n",
    "        LABEL_MAP_NAME = self.paths['OCR_LABELMAP_PATH']\n",
    "        \n",
    "        # Ensure label map directory exists\n",
    "        os.makedirs(LABEL_MAP_NAME, exist_ok=True)\n",
    "\n",
    "        # Create label map\n",
    "        with open(LABEL_MAP_NAME, 'w') as f:\n",
    "            for label in self.LABELS_OCR:\n",
    "                f.write('item { \\n')\n",
    "                f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "                f.write('\\tid:{}\\n'.format(label['id']))\n",
    "                f.write('}\\n')\n",
    "\n",
    "        # Load the TensorFlow saved model\n",
    "        model = tf.saved_model.load(MODEL_PATH)\n",
    "        category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_NAME)\n",
    "        infer = model.signatures['serving_default']\n",
    "\n",
    "        # Read and preprocess the input image\n",
    "        img = cv2.imread(image_path)\n",
    "        image_np = np.array(img)\n",
    "\n",
    "        # Run object detection\n",
    "        detections = self.detect_objects(image_np, infer)\n",
    "\n",
    "        # Process detections\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        # Visualization\n",
    "        label_id_offset = 0\n",
    "        image_np_with_detections = image_np.copy()\n",
    "        min_threshold = 0.2\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes'] + label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=15,\n",
    "            min_score_thresh=min_threshold,\n",
    "            agnostic_mode=False\n",
    "        )\n",
    "\n",
    "        # Get OCR results\n",
    "        textRow1 = self.get_sorted_detected_labels_singleRow(detections, category_index, min_threshold)\n",
    "        textBothRow = self.get_serialized_detected_labels_bothRows(detections, category_index, min_threshold)\n",
    "\n",
    "        # Return OCR results\n",
    "        return textBothRow, textRow1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d95925-883c-404f-8f9d-e2b78d1df403",
   "metadata": {},
   "source": [
    "### ***Create an instance of the performObjectDetection class and define the paths to the image, OCR model, and label map.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa3b0c4-85fc-43d1-9f54-059308a460a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the performObjectDetection class\n",
    "detector = performObjectDetection(loadModels.paths)\n",
    "\n",
    "# Define the paths to the image, OCR model, and label map\n",
    "#image_path = \"path_to_your_image.jpg\"\n",
    "image_path =r'C:\\Users\\Msdn08\\Desktop\\Test_Img\\img (10629).jpg'\n",
    "ocr_model_path = loadModels.paths['OCR_MODEL_PATH']\n",
    "ocr_labelmap_path = loadModels.paths['OCR_LABELMAP_PATH']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50eb77-c616-46d6-a8dd-f7aafb04e1cf",
   "metadata": {},
   "source": [
    "### ***Run object detection and OCR on the image and print the results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be2db0-7896-4369-baa7-943493f89f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run object detection and OCR\n",
    "results = detector.run_object_detection_and_ocr(image_path, ocr_model_path, ocr_labelmap_path)\n",
    "\n",
    "# Print the OCR results\n",
    "for both_row, row1 in results:\n",
    "    print(\"Both Rows:\", both_row)\n",
    "    print(\"Single Row:\", row1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
